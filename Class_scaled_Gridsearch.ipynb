{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataframe in\n",
    "df = pd.read_csv('data/kickstarter_preprocess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['backers_count', 'country', 'goal', 'staff_pick', 'state',\n",
       "       'usd_pledged', 'blurb_len_c', 'blurb_len_w', 'slug_len_c', 'slug_len_w',\n",
       "       'cat_in_slug', 'category_parent_id', 'category_id', 'category_name',\n",
       "       'created_year', 'created_month', 'deadline_year', 'deadline_month',\n",
       "       'launched_year', 'launched_month', 'duration_days', 'preparation',\n",
       "       'pledged_per_backer', 'rel_pledged_goal', 'filled_parent',\n",
       "       'parent_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features to keep: preparation, duration_days, goal, pledged_per_backer, parent_name, blurb_len_w, slug_len_w, 'launched_month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unimportant features\n",
    "df.drop(['backers_count', 'country', 'usd_pledged', 'blurb_len_c', 'slug_len_c', 'cat_in_slug', \n",
    "         'category_parent_id', 'category_id', 'category_name', 'created_year', 'created_month', 'deadline_year', \n",
    "         'deadline_month', 'launched_year', 'rel_pledged_goal', 'filled_parent', 'staff_pick'], \n",
    "        axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['goal', 'state', 'blurb_len_w', 'slug_len_w', 'launched_month',\n",
       "       'duration_days', 'preparation', 'pledged_per_backer', 'parent_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 177593 entries, 0 to 177592\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   goal                177593 non-null  float64\n",
      " 1   state               177593 non-null  object \n",
      " 2   blurb_len_w         177593 non-null  int64  \n",
      " 3   slug_len_w          177593 non-null  int64  \n",
      " 4   launched_month      177593 non-null  int64  \n",
      " 5   duration_days       177593 non-null  int64  \n",
      " 6   preparation         177593 non-null  int64  \n",
      " 7   pledged_per_backer  177593 non-null  int64  \n",
      " 8   parent_name         177593 non-null  object \n",
      "dtypes: float64(1), int64(6), object(2)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop rows with state == canceled, rows with wrong categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168975, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df[df['state'] == \"canceled\" ].index)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82036, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [\"Games\", \"Art\", \"Photography\", \"Film & Video\", \"Design\", \"Technology\"]\n",
    "df = df[df.parent_name.isin(categories)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make dummies (state, category_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.staff_pick = df.staff_pick.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "0    38660\n",
       "1    43376\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['state'] = np.where(df['state'] == 'successful', 1, 0)\n",
    "df.groupby('state').state.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the categorical variable parent_name into dummy/indicator variables\n",
    "df_dum2 = pd.get_dummies(df.parent_name, prefix='parent_name')\n",
    "df = df.drop(['parent_name'], axis=1)\n",
    "df = pd.concat([df, df_dum2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a categorical variable for launched_month q1, q2, q3, q4 \n",
    "df.loc[df['launched_month'] <  4, 'time_yr'] = 'q1'\n",
    "df.loc[(df['launched_month'] >=  4) & (df['launched_month'] <  7), 'time_yr'] = 'q2'\n",
    "df.loc[(df['launched_month'] >=  7) & (df['launched_month'] <  10), 'time_yr'] = 'q3'\n",
    "df.loc[df['launched_month'] >  9, 'time_yr'] = 'q4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dum3 = pd.get_dummies(df.time_yr, prefix='time_yr')\n",
    "df = df.drop(['time_yr'], axis=1)\n",
    "df = df.drop(['launched_month'], axis=1)\n",
    "df = pd.concat([df, df_dum3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['goal', 'state', 'blurb_len_w', 'slug_len_w', 'duration_days',\n",
       "       'preparation', 'pledged_per_backer', 'parent_name_Art',\n",
       "       'parent_name_Design', 'parent_name_Film & Video', 'parent_name_Games',\n",
       "       'parent_name_Photography', 'parent_name_Technology', 'time_yr_q1',\n",
       "       'time_yr_q2', 'time_yr_q3', 'time_yr_q4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82036 entries, 0 to 177591\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   goal                      82036 non-null  float64\n",
      " 1   state                     82036 non-null  int64  \n",
      " 2   blurb_len_w               82036 non-null  int64  \n",
      " 3   slug_len_w                82036 non-null  int64  \n",
      " 4   duration_days             82036 non-null  int64  \n",
      " 5   preparation               82036 non-null  int64  \n",
      " 6   pledged_per_backer        82036 non-null  int64  \n",
      " 7   parent_name_Art           82036 non-null  uint8  \n",
      " 8   parent_name_Design        82036 non-null  uint8  \n",
      " 9   parent_name_Film & Video  82036 non-null  uint8  \n",
      " 10  parent_name_Games         82036 non-null  uint8  \n",
      " 11  parent_name_Photography   82036 non-null  uint8  \n",
      " 12  parent_name_Technology    82036 non-null  uint8  \n",
      " 13  time_yr_q1                82036 non-null  uint8  \n",
      " 14  time_yr_q2                82036 non-null  uint8  \n",
      " 15  time_yr_q3                82036 non-null  uint8  \n",
      " 16  time_yr_q4                82036 non-null  uint8  \n",
      "dtypes: float64(1), int64(6), uint8(10)\n",
      "memory usage: 5.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goal</th>\n",
       "      <th>state</th>\n",
       "      <th>blurb_len_w</th>\n",
       "      <th>slug_len_w</th>\n",
       "      <th>duration_days</th>\n",
       "      <th>preparation</th>\n",
       "      <th>pledged_per_backer</th>\n",
       "      <th>parent_name_Art</th>\n",
       "      <th>parent_name_Design</th>\n",
       "      <th>parent_name_Film &amp; Video</th>\n",
       "      <th>parent_name_Games</th>\n",
       "      <th>parent_name_Photography</th>\n",
       "      <th>parent_name_Technology</th>\n",
       "      <th>time_yr_q1</th>\n",
       "      <th>time_yr_q2</th>\n",
       "      <th>time_yr_q3</th>\n",
       "      <th>time_yr_q4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12160.66</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54737.83</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2602.33</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        goal  state  blurb_len_w  slug_len_w  duration_days  preparation  \\\n",
       "0    1000.00      1           22           4             30            8   \n",
       "2   12160.66      0           23           7             59            5   \n",
       "15  54737.83      0            3           2             20            3   \n",
       "16   2602.33      1           19           3             21            2   \n",
       "18   5000.00      1           25           7             29            0   \n",
       "\n",
       "    pledged_per_backer  parent_name_Art  parent_name_Design  \\\n",
       "0                   41                0                   0   \n",
       "2                   55                0                   0   \n",
       "15                   5                1                   0   \n",
       "16                  38                0                   0   \n",
       "18                  84                1                   0   \n",
       "\n",
       "    parent_name_Film & Video  parent_name_Games  parent_name_Photography  \\\n",
       "0                          0                  1                        0   \n",
       "2                          0                  1                        0   \n",
       "15                         0                  0                        0   \n",
       "16                         0                  0                        1   \n",
       "18                         0                  0                        0   \n",
       "\n",
       "    parent_name_Technology  time_yr_q1  time_yr_q2  time_yr_q3  time_yr_q4  \n",
       "0                        0           0           0           1           0  \n",
       "2                        0           1           0           0           0  \n",
       "15                       0           0           0           1           0  \n",
       "16                       0           0           0           0           1  \n",
       "18                       0           1           0           0           0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.state\n",
    "X = df.drop('state', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to define which columns we want to scale.\n",
    "col_scale = ['goal', 'blurb_len_w', 'slug_len_w', 'duration_days', 'preparation', 'pledged_per_backer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling with standard scaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_st = scaler.fit_transform(X_train[col_scale])\n",
    "X_test_scaled_st = scaler.transform(X_test[col_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating scaled and dummy columns \n",
    "X_train_preprocessed_st = np.concatenate([X_train_scaled_st, X_train.drop(col_scale, axis=1)], axis=1)\n",
    "X_test_preprocessed_st = np.concatenate([X_test_scaled_st, X_test.drop(col_scale, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling with MinMaxScaler\n",
    "\n",
    "# Try to scale you data with the MinMaxScaler() from sklearn. \n",
    "# It follows the same syntax as the StandardScaler.\n",
    "# Don't forget: you have to import the scaler at the top of your notebook. \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled_nor = scaler.fit_transform(X_train[col_scale])\n",
    "X_test_scaled_nor = scaler.transform(X_test[col_scale])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating scaled and dummy columns \n",
    "X_train_preprocessed_nor = np.concatenate([X_train_scaled_nor, X_train.drop(col_scale, axis=1)], axis=1)\n",
    "X_test_preprocessed_nor = np.concatenate([X_test_scaled_nor, X_test.drop(col_scale, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "0    38660\n",
       "1    43376\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('state').state.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Classification and Gridsearch (tuning hyperparameters)\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_preprocessed_st, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test_preprocessed_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5291, 2441],\n",
       "       [1823, 6853]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "#print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71      7732\n",
      "           1       0.74      0.79      0.76      8676\n",
      "\n",
      "    accuracy                           0.74     16408\n",
      "   macro avg       0.74      0.74      0.74     16408\n",
      "weighted avg       0.74      0.74      0.74     16408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# standardization\n",
    "print classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 1000.0, 'penalty': 'l2'}\n",
      "accuracy : 0.7474250324022859\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch https://www.kaggle.com/enespolat/grid-search-with-logistic-regression\n",
    "grid = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]} # l1 lasso l2 ridge\n",
    "logreg = LogisticRegression()\n",
    "logreg_cv = GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train_preprocessed_st,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5311, 2421],\n",
       "       [1772, 6904]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "lr2 = LogisticRegression(C=1000.0,penalty=\"l2\")\n",
    "lr2.fit(X_train_preprocessed_st, y_train)\n",
    "y_pred = lr2.predict(X_test_preprocessed_st)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72      7732\n",
      "           1       0.74      0.80      0.77      8676\n",
      "\n",
      "    accuracy                           0.74     16408\n",
      "   macro avg       0.75      0.74      0.74     16408\n",
      "weighted avg       0.74      0.74      0.74     16408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (65628, 17) (65628,)\n",
      "Test set: (16408, 17) (16408,)\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "print ('Train set:', X_train_preprocessed_st.shape,  y_train.shape)\n",
    "print ('Test set:', X_test_preprocessed_st.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train_preprocessed_st, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72      7732\n",
      "           1       0.74      0.80      0.77      8676\n",
      "\n",
      "    accuracy                           0.74     16408\n",
      "   macro avg       0.75      0.74      0.74     16408\n",
      "weighted avg       0.74      0.74      0.74     16408\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[5311 2421]\n",
      " [1772 6904]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print (classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['failed','successful'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-9daf70f84f16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_preprocessed_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = [{'kernel': ['rbf'], \n",
    "               'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "               'C': [1, 10, 100, 1000]},\n",
    "              {'kernel': ['linear'], \n",
    "               'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "grid = GridSearchCV(clf, param_grid, verbose=True, n_jobs=-1)\n",
    "\n",
    "result = grid.fit(X_train_preprocessed_st, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best parameters \n",
    "print('Best Parameters:', result.best_params_)\n",
    "\n",
    "# Print best score\n",
    "print('Best Score:', result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = svm.SVC(kernel='rbf')\n",
    "clf2.fit(X_train_preprocessed_st, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print (classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['failed','successful'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               random_state=42, \n",
    "                               max_features = 'sqrt',\n",
    "                               n_jobs=-1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt', n_jobs=-1, random_state=42,\n",
       "                       verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on training data\n",
    "model.fit(X_train_preprocessed_st, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_preprocessed_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Training predictions (to demonstrate overfitting)\n",
    "train_rf_predictions = model.predict(X_train_preprocessed_st)\n",
    "train_rf_probs = model.predict_proba(X_train_preprocessed_st)[:, 1]\n",
    "\n",
    "# Testing predictions (to determine performance)\n",
    "rf_predictions = model.predict(X_test_preprocessed_st)\n",
    "rf_probs = model.predict_proba(X_test_preprocessed_st)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79      7732\n",
      "           1       0.79      0.89      0.84      8676\n",
      "\n",
      "    accuracy                           0.81     16408\n",
      "   macro avg       0.82      0.81      0.81     16408\n",
      "weighted avg       0.82      0.81      0.81     16408\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0c93fa83bdb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Plot non-normalized confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'failed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'successful'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Confusion matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_confusion_matrix' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print (classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['failed','successful'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79      7732\n",
      "           1       0.79      0.89      0.84      8676\n",
      "\n",
      "    accuracy                           0.81     16408\n",
      "   macro avg       0.82      0.81      0.81     16408\n",
      "weighted avg       0.82      0.81      0.81     16408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest: Optimization through Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  30 | elapsed:   37.8s remaining:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   49.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [None, 3, 3, 3, 4, 4, 4, 5,\n",
       "                                                      5, 5, 6, 6, 6, 7, 7, 7, 8,\n",
       "                                                      8, 8, 9, 9, 9, 10, 10, 10,\n",
       "                                                      11, 11, 12, 12, 12, ...],\n",
       "                                        'max_features': ['auto', 'sqrt', None,\n",
       "                                                         0.5, 0.6, 0.7,\n",
       "                                                         0.7999999999999999,\n",
       "                                                         0.8999999999999999],\n",
       "                                        'max_leaf_nodes': [None, 10, 10, 10, 10,\n",
       "                                                           10, 10, 10, 10, 10,\n",
       "                                                           10, 10, 10, 10, 11,\n",
       "                                                           11, 11, 11, 11, 11,\n",
       "                                                           11, 11, 11, 11, 11,\n",
       "                                                           11, 12, 12, 12, 12, ...],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': array([ 10,  13,  17,  21,  25,  29,  33,  37,  41,  44,  48,  52,  56,\n",
       "        60,  64,  68,  72,  75,  79,  83,  87,  91,  95,  99, 103, 106,\n",
       "       110, 114, 118, 122, 126, 130, 134, 137, 141, 145, 149, 153, 157,\n",
       "       161, 165, 168, 172, 176, 180, 184, 188, 192, 196, 200])},\n",
       "                   random_state=42, scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': np.linspace(10, 200).astype(int),\n",
    "    'max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n",
    "    'max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n",
    "    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Estimator for use in random search\n",
    "estimator = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "# Create the random search model\n",
    "rs = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n",
    "                        scoring = 'roc_auc', cv = 3, \n",
    "                        n_iter = 10, verbose = 5, random_state=42)\n",
    "\n",
    "# Fit \n",
    "rs.fit(X_train_preprocessed_st, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 196,\n",
       " 'min_samples_split': 10,\n",
       " 'max_leaf_nodes': 49,\n",
       " 'max_features': 0.7,\n",
       " 'max_depth': 17,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=196, \n",
    "                               random_state=42, \n",
    "                               min_samples_split=10,\n",
    "                               max_leaf_nodes=49,\n",
    "                               max_features=0.7,\n",
    "                               max_depth=17,\n",
    "                               bootstrap=True,\n",
    "                               n_jobs=-1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 196 out of 196 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=17, max_features=0.7, max_leaf_nodes=49,\n",
       "                       min_samples_split=10, n_estimators=196, n_jobs=-1,\n",
       "                       random_state=42, verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on training data\n",
    "model.fit(X_train_preprocessed_st, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 196 out of 196 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_preprocessed_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 196 out of 196 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 196 out of 196 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 196 out of 196 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 196 out of 196 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Training predictions (to demonstrate overfitting)\n",
    "train_rf_predictions = model.predict(X_train_preprocessed_st)\n",
    "train_rf_probs = model.predict_proba(X_train_preprocessed_st)[:, 1]\n",
    "\n",
    "# Testing predictions (to determine performance)\n",
    "rf_predictions = model.predict(X_test_preprocessed_st)\n",
    "rf_probs = model.predict_proba(X_test_preprocessed_st)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.77      7732\n",
      "           1       0.77      0.92      0.84      8676\n",
      "\n",
      "    accuracy                           0.81     16408\n",
      "   macro avg       0.83      0.80      0.81     16408\n",
      "weighted avg       0.82      0.81      0.81     16408\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-0c93fa83bdb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Plot non-normalized confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'failed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'successful'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Confusion matrix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_confusion_matrix' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print (classification_report(y_test, y_pred))\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['failed','successful'],normalize= False,  title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rf_predictions = best_model.predict(X_train_preprocessed_st)\n",
    "train_rf_probs = best_model.predict_proba(X_train_preprocessed_st)[:, 1]\n",
    "\n",
    "rf_predictions = best_model.predict(X_test_preprocessed_st)\n",
    "rf_probs = best_model.predict_proba(X_test_preprocessed_st)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of nodes 97\n",
      "Average maximum depth 10\n"
     ]
    }
   ],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "\n",
    "for ind_tree in best_model.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(predictions, probs, train_predictions, train_probs):\n",
    "    \"\"\"Compare machine learning model to baseline performance.\n",
    "    Computes statistics and shows ROC curve.\"\"\"\n",
    "    \n",
    "    baseline = {}\n",
    "    \n",
    "    baseline['recall'] = recall_score(y_test, [1 for _ in range(len(y_test))])\n",
    "    baseline['precision'] = precision_score(y_test, [1 for _ in range(len(y_test))])\n",
    "    baseline['roc'] = 0.5\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['recall'] = recall_score(y_test, predictions)\n",
    "    results['precision'] = precision_score(y_test, predictions)\n",
    "    results['roc'] = roc_auc_score(y_test, probs)\n",
    "    \n",
    "    train_results = {}\n",
    "    train_results['recall'] = recall_score(y_train, train_predictions)\n",
    "    train_results['precision'] = precision_score(y_train, train_predictions)\n",
    "    train_results['roc'] = roc_auc_score(y_train, train_probs)\n",
    "    \n",
    "    for metric in ['recall', 'precision', 'roc']:\n",
    "        print(f'{metric.capitalize()} Baseline: {round(baseline[metric], 2)} Test: {round(results[metric], 2)} Train: {round(train_results[metric], 2)}')\n",
    "    \n",
    "    # Calculate false positive rates and true positive rates\n",
    "    base_fpr, base_tpr, _ = roc_curve(y_test, [1 for _ in range(len(y_test))])\n",
    "    model_fpr, model_tpr, _ = roc_curve(y_test, probs)\n",
    "\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    \n",
    "    # Plot both curves\n",
    "    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n",
    "    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n",
    "    plt.legend();\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curves');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recall_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-8497c45415b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rf_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rf_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-c51d647599f3>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(predictions, probs, train_predictions, train_probs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbaseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mbaseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbaseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'recall_score' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf_predictions, rf_probs, train_rf_predictions, train_rf_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
